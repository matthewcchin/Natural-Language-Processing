We performed sentiment analysis on a review dataset using pretrained models, VADER and TextBlob. The process included data exploration, text cleaning, tokenization, vectorization, and model application. We compared model results on 100 random samples and evaluated them based on performance criteria like accuracy and speed. The project highlights the importance of human review alongside automated NLP models.
